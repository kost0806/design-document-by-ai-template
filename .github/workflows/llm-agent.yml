name: LLM Agent Workflow

on:
  issues:
    types: [labeled]

jobs:
  run-claude:
    if: startsWith(github.event.label.name, 'claude:')
    runs-on: ubuntu-latest
    permissions:
      issues: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Anthropic SDK
        run: |
          pip install anthropic

      - name: Run Claude via API
        id: claude
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          LABEL_NAME: ${{ github.event.label.name }}
          ISSUE_BODY: ${{ github.event.issue.body }}
        run: |
          # Extract model from label (claude:model-name -> model-name)
          MODEL=$(echo "$LABEL_NAME" | cut -d':' -f2)
          echo "Using Claude model: $MODEL"

          cat > run_claude.py << 'SCRIPT'
          import anthropic
          import os
          import sys

          # Get model from environment (use label value directly)
          model = os.environ.get('MODEL', 'claude-sonnet-4')
          issue_body = os.environ.get('ISSUE_BODY', '')
          api_key = os.environ.get('ANTHROPIC_API_KEY', '')

          print(f"Using model: {model}", file=sys.stderr)

          # System instruction
          system_instruction = """You are an AI assistant helping with GitHub issue analysis. Your response will be posted as a GitHub issue comment.

          IMPORTANT GUIDELINES:
          - Keep your response concise and well-structured
          - Use Markdown formatting (headers, lists, code blocks)
          - Summarize key points instead of lengthy explanations
          - Focus on actionable insights and clear recommendations
          - Maximum length: 2000 words
          - Use emojis sparingly for better readability

          Structure your response as:
          ## ðŸ“ Summary
          [Brief overview in 2-3 sentences]

          ## ðŸŽ¯ Key Points
          - [Main point 1]
          - [Main point 2]
          - [Main point 3]

          ## ðŸ’¡ Recommendations
          [Specific actionable items]
          """

          try:
              client = anthropic.Anthropic(api_key=api_key)

              message = client.messages.create(
                  model=model,
                  max_tokens=4096,
                  system=system_instruction,
                  messages=[
                      {"role": "user", "content": issue_body}
                  ]
              )

              print(message.content[0].text)
          except Exception as e:
              print(f"Error: {str(e)}", file=sys.stderr)
              sys.exit(1)
          SCRIPT

          # Pass model to Python script
          export MODEL="$MODEL"

          # Run the script and capture output
          python run_claude.py > result.txt 2>&1 || echo "Error: Failed to run Claude with model '$MODEL'" > result.txt

          # Read result
          RESULT=$(cat result.txt)
          echo "RESULT<<EOF" >> $GITHUB_OUTPUT
          echo "$RESULT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
        continue-on-error: true

      - name: Comment result on issue
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const result = `${{ steps.claude.outputs.RESULT }}`;
            const truncated = result.length > 60000 ? result.substring(0, 60000) + '\n\n... (truncated)' : result;

            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: `## ðŸ¤– Claude Code Result\n\n**Prompt:**\n> ${context.payload.issue.body.substring(0, 500)}${context.payload.issue.body.length > 500 ? '...' : ''}\n\n**Response:**\n\`\`\`\n${truncated}\n\`\`\``
            });

  run-gemini:
    if: startsWith(github.event.label.name, 'gemini:')
    runs-on: ubuntu-latest
    permissions:
      issues: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Gemini CLI
        run: |
          pip install google-generativeai

      - name: Run Gemini
        id: gemini
        env:
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
          LABEL_NAME: ${{ github.event.label.name }}
          ISSUE_BODY: ${{ github.event.issue.body }}
        run: |
          # Extract model from label (gemini:model-name -> model-name)
          MODEL=$(echo "$LABEL_NAME" | cut -d':' -f2)
          echo "Using Gemini model: $MODEL"

          cat > run_gemini.py << 'SCRIPT'
          import google.generativeai as genai
          import os
          import sys

          genai.configure(api_key=os.environ['GOOGLE_API_KEY'])

          # Get model from environment
          selected_model = os.environ.get('MODEL', 'gemini-2.0-flash-exp')
          issue_body = os.environ.get('ISSUE_BODY', '')

          print(f"Using model: {selected_model}", file=sys.stderr)

          # System instruction for concise GitHub comment responses
          system_instruction = """You are an AI assistant helping with GitHub issue analysis. Your response will be posted as a GitHub issue comment.

          IMPORTANT GUIDELINES:
          - Keep your response concise and well-structured
          - Use Markdown formatting (headers, lists, code blocks)
          - Summarize key points instead of lengthy explanations
          - Focus on actionable insights and clear recommendations
          - Maximum length: 2000 words
          - Use emojis sparingly for better readability

          Structure your response as:
          ## ðŸ“ Summary
          [Brief overview in 2-3 sentences]

          ## ðŸŽ¯ Key Points
          - [Main point 1]
          - [Main point 2]
          - [Main point 3]

          ## ðŸ’¡ Recommendations
          [Specific actionable items]
          """

          try:
              model = genai.GenerativeModel(
                  selected_model,
                  system_instruction=system_instruction
              )

              response = model.generate_content(issue_body)
              print(response.text)
          except Exception as e:
              print(f"Error: {str(e)}", file=sys.stderr)
              sys.exit(1)
          SCRIPT

          # Pass model to Python script
          export MODEL="$MODEL"

          # Run the script and capture output
          python run_gemini.py > result.txt 2>&1 || echo "Error: Failed to run Gemini with model '$MODEL'" > result.txt

          # Read result
          RESULT=$(cat result.txt)
          echo "RESULT<<EOF" >> $GITHUB_OUTPUT
          echo "$RESULT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
        continue-on-error: true

      - name: Comment result on issue
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const result = `${{ steps.gemini.outputs.RESULT }}`;
            const truncated = result.length > 60000 ? result.substring(0, 60000) + '\n\n... (truncated)' : result;

            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: `## ðŸ¤– Gemini Result\n\n**Prompt:**\n> ${context.payload.issue.body.substring(0, 500)}${context.payload.issue.body.length > 500 ? '...' : ''}\n\n**Response:**\n\`\`\`\n${truncated}\n\`\`\``
            });
